{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e382b0b",
   "metadata": {},
   "source": [
    "# Importing modules and lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a636d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random as random\n",
    "import re\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from MY_FUNCTIONS import *\n",
    "import seaborn as sns\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "# Load local paths and variables\n",
    "data = None\n",
    "with open(\"config.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "    \n",
    "input_path = join(data[\"general\"][\"input_path\"], \"speech_rate\")\n",
    "output_path = join(data[\"general\"][\"output_path\"], \"speech_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18e2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv(join(input_path, 'Lexique383\\\\Lexique383.tsv'), sep='\\t')\n",
    "lexicon = lexicon[['ortho', 'nbsyll']]\n",
    "dictionnary = dict(zip(lexicon['ortho'], lexicon ['nbsyll']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f4cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_path = join(output_path, \"plots\")\n",
    "examples_path = join(output_path, \"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cf160",
   "metadata": {},
   "source": [
    "# Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad0831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_silences = 0  #silences between words of a same utterance\n",
    "remove_shorter = 1  #utterances with only one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964d3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_red = (0.8,0,0)\n",
    "my_blue= (0,0.4,0.8)\n",
    "my_pink = (1,0.4,0.4)\n",
    "my_green = (0,0.8,0.4)\n",
    "my_purple = (0.6,0,0.3)\n",
    "my_yellow = (0.89, 0.75, 0)\n",
    "my_orange = (0.82, 0.55, 0)\n",
    "my_turquoise = (0, 0.72, 0.58)\n",
    "my_bordeaux = (0.51, 0.02, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4565a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = [my_red, my_blue, my_pink, my_green, my_purple, my_yellow, my_orange, my_turquoise, my_bordeaux]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac6fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_window = 9\n",
    "default_poly = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06cb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_AA = join(input_path, 'Corrected transcriptions\\\\AA')\n",
    "path_CA = join(input_path, 'Corrected transcriptions\\\\CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c46181",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35404661",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = pd.read_csv(join(input_path, \"word.csv\"))\n",
    "WORDS = WORDS[WORDS['Length']!=0] #to keep only non-zero intervals\n",
    "filenames = WORDS['Filename'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6827df",
   "metadata": {},
   "source": [
    "# Separating AA and CA files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18bd23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_AA = []\n",
    "WORDS_CA = []\n",
    "for filename in filenames : \n",
    "    WORDS_file = WORDS[ WORDS['Filename']==filename][['Word','UtteranceName','Speaker', 'Length', 'Global_start', 'Filename', 'Global_end']]\n",
    "    WORDS_file.reset_index(drop=True, inplace=True)\n",
    "    WORDS_file=WORDS_file.sort_values('Speaker', ascending=True)\n",
    "    if filename[0:2]=='AA':\n",
    "        WORDS_AA.append(WORDS_file)\n",
    "    else:\n",
    "        WORDS_CA.append(WORDS_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b16e6",
   "metadata": {},
   "source": [
    "# Creating a csv file for each conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b7d5c",
   "metadata": {},
   "source": [
    "## Computing the \"syllables\" column, and grouping words by utterances (keeping the first start and last end, summing syllables and length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c88ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,WORDS in enumerate(WORDS_AA) :\n",
    "        \n",
    "    list_syll = []\n",
    "    for word in WORDS['Word']:\n",
    "        word=word.lower()\n",
    "        if word in dictionnary:\n",
    "            list_syll.append(dictionnary[word])\n",
    "        else : \n",
    "            list_syll.append(estimate_syll(word))\n",
    "            \n",
    "    WORDS[\"syllables\"] = list_syll\n",
    "    WORDS=WORDS.sort_values('Global_start', ascending=True)\n",
    "    WORDS_AA[i] = WORDS\n",
    "        \n",
    "    table = pd.pivot_table(WORDS, values = ['Length', 'Global_start', 'Global_end','syllables', 'Speaker', 'Filename', 'Word'], index = ['UtteranceName'], aggfunc = {'Length':np.sum, 'Global_start':min, 'syllables':np.sum, 'Speaker' : np.min, 'Filename':np.min, 'Word':'count', 'Global_end':max})\n",
    "    table = table.sort_values('Global_start', ascending = True)\n",
    "    if remove_silences:\n",
    "        table['Speech rate'] = table['syllables']/table['Length']\n",
    "    else:\n",
    "        table['Speech rate'] = table['syllables']/(table['Global_end']-table['Global_start'])\n",
    "    if remove_shorter:\n",
    "        table = table[ table['Word']>1]\n",
    "    WORDS_AA[i] = table\n",
    "    table.to_csv(join(path_AA, str(WORDS['Filename'][0])+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63215483",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,WORDS in enumerate(WORDS_CA) : \n",
    "        \n",
    "    list_syll = []\n",
    "    for word in WORDS['Word']:\n",
    "        word=str(word)\n",
    "        word = word.lower()\n",
    "        if word in dictionnary:\n",
    "            list_syll.append(dictionnary[word])\n",
    "        else : \n",
    "            list_syll.append(estimate_syll(word))\n",
    "    WORDS[\"syllables\"] = list_syll\n",
    "    WORDS_CA[i] = WORDS\n",
    "    \n",
    "    WORDS['Word'] = np.vectorize(str)(WORDS['Word'])\n",
    "    WORDS.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    table = pd.pivot_table(WORDS, values = ['Word', 'UtteranceName', 'Global_start', 'Global_end', 'Length', \"Filename\", \"syllables\"], index = ['UtteranceName', \"Speaker\"], aggfunc = {\"Global_end\":max,\"UtteranceName\":np.unique,'Word':'count', 'Global_start':min, \"Length\":sum, \"Speaker\":np.unique, \"Filename\":np.unique, \"syllables\":sum})    \n",
    "    table = table.sort_values('Global_start', ascending = True)\n",
    "    \n",
    "    if remove_silences :\n",
    "        table['Speech rate'] = table['syllables']/table['Length']\n",
    "    else : \n",
    "        table['Speech rate'] = table['syllables']/(table['Global_end']-table['Global_start'])\n",
    "    if remove_shorter:\n",
    "        table = table[ table['Word']>1]\n",
    "    WORDS_CA[i] = table\n",
    "    \n",
    "    table.to_csv(join(path_CA, str(WORDS['Filename'][0])+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3b1e1",
   "metadata": {},
   "source": [
    "# Importing the new csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af7b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-AN-DL.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-GD-DD.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-JL-AZ.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-LA-AN.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-LD-BF.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-MG-CH.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-MJ-CJ.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-ML-MP.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\AA\\AA-XA-EH.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_AA = Path(path_AA).glob('**/*.csv')\n",
    "data_AA = []\n",
    "filenames_AA = []\n",
    "\n",
    "for path in pathlist_AA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        filenames_AA.append(str(path)[-12:-4])\n",
    "        data_AA.append(pd.read_csv(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dc9cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-AN-ZN.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-FB-MG.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-JL-JT.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-LD-GD.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-LJ-MJ.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-MB-LB.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-MD-GD.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-RL-ML.csv\n",
      "input\\speech_rate\\Corrected transcriptions\\CA\\CA-XA-LA.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_CA = Path(path_CA).glob('**/*.csv')\n",
    "data_CA = []\n",
    "filenames_CA = []\n",
    "\n",
    "for path in pathlist_CA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        filenames_CA.append(str(path)[-12:-4])\n",
    "        data_CA.append(pd.read_csv(path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc093d",
   "metadata": {},
   "source": [
    "# Raw speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf4563a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs1 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, data in enumerate(data_AA) :\n",
    "    \n",
    "    data_1 = data[ data['Speaker'] == \"Adult1\" ]\n",
    "    data_2 = data[ data['Speaker'] == \"Adult2\" ]\n",
    "    \n",
    "    axs1[i//3,i%3].set_title(data['Filename'][0])\n",
    "    axs1[i//3,i%3].set_xlabel('Time (sec)')\n",
    "    axs1[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs1[i//3,i%3].plot(data_1['Global_start'], data_1['Speech rate'], label=\"Adult1\", color=my_blue)\n",
    "    axs1[i//3,i%3].plot(data_2['Global_start'], data_2['Speech rate'], label=\"Adult2\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig1)\n",
    "fig1.savefig(plots_path+\"Raw AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad34c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, data in enumerate(data_CA) :\n",
    "    \n",
    "    data_1 = data[ data['Speaker'] == \"Parent\" ]\n",
    "    data_2 = data[ data['Speaker'] == \"Child\" ]\n",
    "    \n",
    "    axs2[i//3,i%3].set_title(data['Filename'][0])\n",
    "    axs2[i//3,i%3].set_xlabel('Time (sec)')\n",
    "    axs2[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs2[i//3,i%3].plot(data_1['Global_start'], data_1['Speech rate'], label=\"Parent\", color=my_blue)\n",
    "    axs2[i//3,i%3].plot(data_2['Global_start'], data_2['Speech rate'], label=\"Child\", color=my_red)\n",
    "    \n",
    "fig2.tight_layout()\n",
    "plt.close(fig2)\n",
    "fig2.savefig(plots_path+\"Raw CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6df9c",
   "metadata": {},
   "source": [
    "# Fourier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f89dca",
   "metadata": {},
   "source": [
    "# Smoothed speech rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84840082",
   "metadata": {},
   "source": [
    "## With a smoothing window of 10 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b46870",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axs3 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, table in enumerate(data_AA) :\n",
    "    \n",
    "    axs3[i//3,i%3].set_xlabel('time')\n",
    "    axs3[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs3[i//3,i%3].plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], 29, 3), label='Adult1',color = my_red)\n",
    "    axs3[i//3,i%3].plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], 29, 3), label='Adult2', color=my_blue)\n",
    "    axs3[i//3,i%3].set_title(str(table['Filename'][0]))\n",
    "    axs3[i//3,i%3].legend()\n",
    "    \n",
    "    if \"AA-LD-BF\" in filenames_AA[i]:\n",
    "        fig35 = plt.figure()\n",
    "        plt.plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], 29, 3), label='Adult1',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], 29, 3), label='Adult2', color=my_blue)\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Speech rate (syllables/s)\")\n",
    "        plt.close(fig35)\n",
    "        fig35.savefig(plots_path+\"Smoothed AA\")\n",
    "    \n",
    "fig3.tight_layout()\n",
    "plt.close(fig3)\n",
    "fig3.savefig(plots_path+\"Smoothed AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39380d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axs4 = plt.subplots(3, 3, figsize=(20,15))\n",
    "\n",
    "for i, table in enumerate(data_CA) :\n",
    "    \n",
    "    axs4[i//3,i%3].set_xlabel('time')\n",
    "    axs4[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs4[i//3,i%3].plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'],29, 3), label='Parent',color = my_red)\n",
    "    axs4[i//3,i%3].plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], 29, 3), label='Child', color=my_blue)\n",
    "    axs4[i//3,i%3].set_title(str(table['Filename'][0]))\n",
    "    axs4[i//3,i%3].legend()\n",
    "    \n",
    "    if \"CA-LD-GD\" in filenames_CA[i]:\n",
    "        fig45 = plt.figure()\n",
    "        plt.plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'], 29, 3), label='Parent',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], 29, 3), label='Child', color=my_blue)\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Speech rate (syllables/s)\")\n",
    "        plt.close(fig45)\n",
    "        fig45.savefig(plots_path+\"Smoothed CA\")\n",
    "    \n",
    "fig4.tight_layout()\n",
    "plt.close(fig4)\n",
    "fig4.savefig(plots_path+\"Smoothed CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5286b5",
   "metadata": {},
   "source": [
    "# \"Adapted\" speech rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be785b00",
   "metadata": {},
   "source": [
    "## To compute the correlation, the time series must have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807caaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listes_roles = []\n",
    "for i, data in enumerate(data_CA):\n",
    "    liste_role = []\n",
    "    for i in range(len(data)):\n",
    "        liste_role.append((data['Speaker'][i], data['Global_start'][i]))\n",
    "    listes_roles.append(liste_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e61d08",
   "metadata": {},
   "source": [
    "### Loading manual phases notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bd8cdb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_AA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[43mglob_path\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMY_ANNOTATIONS_AA.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m lines_AA \u001b[38;5;241m=\u001b[39m text_AA\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m Filenames_AA \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob_path' is not defined"
     ]
    }
   ],
   "source": [
    "text_AA = open(input_path + \"MY_ANNOTATIONS_AA.txt\", 'r').read()\n",
    "\n",
    "lines_AA = text_AA.split('\\n')\n",
    "Filenames_AA = []\n",
    "Phases_AA = []\n",
    "line = lines_AA[0]\n",
    "file = []\n",
    "for line in lines_AA:\n",
    "    if line!='' and line!=' ':\n",
    "        if \"END\" not in line :\n",
    "            if \"FILENAME\" not in line:\n",
    "                label, time_string = line.split('[')\n",
    "                time_string = time_string.replace('[', '')\n",
    "                time_string = time_string.replace(']', '')\n",
    "                time_string = time_string.replace(' ', '')\n",
    "                time = conversion_time(time_string)\n",
    "                file.append([label, time])\n",
    "            else:\n",
    "                NOM, filename = line.split(' ')\n",
    "        else:\n",
    "            Filenames_AA.append(filename)\n",
    "            Phases_AA.append(file)\n",
    "            file=[]\n",
    "phases_AA = pd.DataFrame(list(zip(Filenames_AA, Phases_AA)), columns = ['Filename', 'Phases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c34f827",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input\\\\speech_rateMY_ANNOTATIONS_CA.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_CA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMY_ANNOTATIONS_CA.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m lines_CA \u001b[38;5;241m=\u001b[39m text_CA\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m Filenames_CA \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input\\\\speech_rateMY_ANNOTATIONS_CA.txt'"
     ]
    }
   ],
   "source": [
    "text_CA = open(input_path + \"MY_ANNOTATIONS_CA.txt\", 'r').read()\n",
    "\n",
    "lines_CA = text_CA.split('\\n')\n",
    "Filenames_CA = []\n",
    "Phases_CA = []\n",
    "line = lines_CA[0]\n",
    "file = []\n",
    "for line in lines_CA:\n",
    "    if line!='' and line!=' ':\n",
    "        if \"END\" not in line :\n",
    "            if \"FILENAME\" not in line:\n",
    "                label, time_string = line.split('[')\n",
    "                time_string = time_string.replace('[', '')\n",
    "                time_string = time_string.replace(']', '')\n",
    "                time_string = time_string.replace(' ', '')\n",
    "                time = conversion_time(time_string)\n",
    "                file.append([label, time])\n",
    "            else:\n",
    "                NOM, filename = line.split(' ')\n",
    "        else:\n",
    "            Filenames_CA.append(filename)\n",
    "            Phases_CA.append(file)\n",
    "            file=[]\n",
    "phases_CA = pd.DataFrame(list(zip(Filenames_CA, Phases_CA)), columns = ['Filename', 'Phases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25465f43",
   "metadata": {},
   "source": [
    "### Adding phases, roles and smoothed columns, save as csv, and adapt the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,filename in enumerate(filenames_AA):\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    data = data_AA[i]\n",
    "    \n",
    "    adapted_data = adapt_points_3(data,\"Speaker\", \"Global_start\", \"Speech rate\")\n",
    "    \n",
    "    liste_phases = list(phases_AA[phases_AA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    adapted_data['Phases'] = find_phases(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data['Roles'] = find_roles(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data[\"Word\"] = data[\"Word\"]\n",
    "    \n",
    "    adapted_data[\"smoothed\"] = smoothed_column(adapted_data, default_window, 'AA')\n",
    "    \n",
    "    adapted_data.to_csv(path_AA+str(filename)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,filename in enumerate(filenames_CA):\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    data = data_CA[i]\n",
    "    \n",
    "    adapted_data = adapt_points_3(data,\"Speaker\", \"Global_start\", \"Speech rate\")\n",
    "    \n",
    "    liste_phases = list(phases_CA[phases_CA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    adapted_data['Phases'] = find_phases(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data['Roles'] = find_roles(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data[\"Word\"] = data[\"Word\"]\n",
    "    \n",
    "    adapted_data[\"smoothed\"] = smoothed_column(adapted_data, default_window, 'CA')\n",
    "        \n",
    "    adapted_data.to_csv(path_CA+str(filename)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c59e65",
   "metadata": {},
   "source": [
    "### Importing the new csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist_AA = Path(path_AA).glob('**/*.csv')\n",
    "adapted_data_AA = []\n",
    "adapted_filenames_AA = []\n",
    "\n",
    "for path in pathlist_AA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        adapted_filenames_AA.append(str(path)[-12:-4])\n",
    "        adapted_data_AA.append(pd.read_csv(path))\n",
    "print(adapted_data_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f992e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist_CA = Path(path_CA).glob('**/*.csv')\n",
    "adapted_data_CA = []\n",
    "adapted_filenames_CA = []\n",
    "\n",
    "for path in pathlist_CA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        adapted_filenames_CA.append(str(path)[-12:-4])\n",
    "        adapted_data_CA.append(pd.read_csv(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261c00b",
   "metadata": {},
   "source": [
    "### Plot of the adapted speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdec7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, axs5 = plt.subplots(9, 2, figsize=(15,20))\n",
    "\n",
    "for i, adapted_data in enumerate(adapted_data_AA) :\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Adult1\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Adult2\" ]  \n",
    "\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Adult1\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Adult2\" ]\n",
    "    \n",
    "    axs5[i,0].set_title(filename+\" speaker1\")\n",
    "    axs5[i,0].set_xlabel('Time (sec)')\n",
    "    axs5[i,0].set_ylabel('Speech rate')\n",
    "    axs5[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'], label=\"Raw\", color=my_blue)\n",
    "    axs5[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'],'o', label=\"Adapted\", color=my_red)\n",
    "    \n",
    "    axs5[i,1].set_title(filename+\" speaker2\")\n",
    "    axs5[i,1].set_xlabel('Time (sec)')\n",
    "    axs5[i,1].set_ylabel('Adapted speech rate')\n",
    "    axs5[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'],label=\"Raw\", color=my_blue)\n",
    "    axs5[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'], 'o',label=\"Adapted\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig5)\n",
    "fig5.savefig(plots_path+\"Adapted AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e512bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, axs6 = plt.subplots(9, 2, figsize=(15,20))\n",
    "\n",
    "for i, adapted_data in enumerate(adapted_data_CA) :\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Parent\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Child\" ]  \n",
    "\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Parent\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Child\" ]\n",
    "    \n",
    "    axs6[i,0].set_title(filename+\" speaker1\")\n",
    "    axs6[i,0].set_xlabel('Time (sec)')\n",
    "    axs6[i,0].set_ylabel('Speech rate')\n",
    "    axs6[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'], label=\"Raw\", color=my_blue)\n",
    "    axs6[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'],'o', label=\"Adapted\", color=my_red)\n",
    "    \n",
    "    axs6[i,1].set_title(filename+\" speaker2\")\n",
    "    axs6[i,1].set_xlabel('Time (sec)')\n",
    "    axs6[i,1].set_ylabel('Adapted speech rate')\n",
    "    axs6[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'],label=\"Raw\", color=my_blue)\n",
    "    axs6[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'], 'o',label=\"Adapted\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig6)\n",
    "fig6.savefig(plots_path+\"Adapted CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145896df",
   "metadata": {},
   "source": [
    "# Global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263adb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for data in adapted_data_AA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "    \n",
    "    data_1 = data[data['Speaker']==speaker1]['Speech rate']\n",
    "    data_2 = data[data['Speaker']==speaker2]['Speech rate']\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(np.array(data_1), np.array(data_2))\n",
    "    correlation_list_AA.append(correlation)\n",
    "    p_values_AA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93155f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    corr = correlation_list_AA[i]\n",
    "    p_value = p_values_AA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig7)\n",
    "fig7.savefig(plots_path+\"Global AA correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317dbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for data in adapted_data_CA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "    \n",
    "    data_1 = data[data['Speaker']==speaker1]['Speech rate']\n",
    "    data_2 = data[data['Speaker']==speaker2]['Speech rate']\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(np.array(data_1), np.array(data_2))\n",
    "    correlation_list_CA.append(correlation)\n",
    "    p_values_CA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02191da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig8 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    corr = correlation_list_CA[i]\n",
    "    p_value = p_values_CA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o',color=my_colors[i], label=filename)\n",
    "    plt.plot([\"p_value\"], [p_value], 'o', color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig8)\n",
    "fig8.savefig(plots_path+\"Global CA correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84780e4",
   "metadata": {},
   "source": [
    "## Global correlation with default window smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for data in adapted_data_AA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "\n",
    "    data_1 = data[data['Speaker']==speaker1]\n",
    "    data_2 = data[data['Speaker']==speaker2]\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(smooth_2(data_1['Speech rate'], default_window, default_poly), smooth_2(data_2['Speech rate'], default_window, default_poly))\n",
    "\n",
    "    correlation_list_AA.append(correlation)\n",
    "    p_values_AA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    corr = correlation_list_AA[i]\n",
    "    p_value = p_values_AA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig9)\n",
    "fig9.savefig(plots_path+\"Global AA smoothed correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97621c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for data in adapted_data_CA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "\n",
    "    data_1 = data[data['Speaker']==speaker1]\n",
    "    data_2 = data[data['Speaker']==speaker2]\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(smooth_2(data_1['Speech rate'], default_window, default_poly), smooth_2(data_2['Speech rate'], default_window, default_poly))\n",
    "\n",
    "    correlation_list_CA.append(correlation)\n",
    "    p_values_CA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig10 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    corr = correlation_list_CA[i]\n",
    "    p_value = p_values_CA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig10)\n",
    "fig10.savefig(plots_path+\"Global CA smoothed correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbaa7b4",
   "metadata": {},
   "source": [
    "# Influence of the smoothing window on global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70597100",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.arange(5, 25, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    correlation_file = []\n",
    "    p_value_file = []\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data1  = data[data['Speaker']=='Adult1']\n",
    "    data2  = data[data['Speaker']=='Adult2']\n",
    "    \n",
    "    for window in windows :\n",
    "        \n",
    "        corr, p_value = stats.pearsonr(smooth_2(data1['Speech rate'], window, default_poly), smooth_2(data2['Speech rate'], window, default_poly))\n",
    "        correlation_file.append(corr)\n",
    "        p_value_file.append(p_value)\n",
    "        \n",
    "    correlations_AA.append(correlation_file)\n",
    "    p_values_AA.append(p_value_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e058cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig11 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "\n",
    "    plt.plot(windows, correlations_AA[i], label=filename, color=my_colors[i])\n",
    "    #plt.plot(windows, p_values_AA[i], '--',color=my_colors[i])\n",
    "\n",
    "plt.xlabel(\"smoothing window\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.legend()\n",
    "plt.close(fig11)\n",
    "fig11.savefig(plots_path+\"Window influence on correlation AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52026186",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    correlation_file = []\n",
    "    p_values_file = []\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data1  = data[data['Speaker']=='Parent']\n",
    "    data2  = data[data['Speaker']=='Child']\n",
    "    \n",
    "    for window in windows :\n",
    "        \n",
    "        corr, p_value = stats.pearsonr(smooth_2(data1['Speech rate'], window, default_poly), smooth_2(data2['Speech rate'], window, default_poly))\n",
    "        correlation_file.append(corr)\n",
    "        p_values_file.append(p_value)\n",
    "        \n",
    "    correlations_CA.append(correlation_file)\n",
    "    p_values_CA.append(p_values_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig12 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "\n",
    "    plt.plot(windows, correlations_CA[i], label=filename, color=my_colors[i])\n",
    "    #plt.plot(windows, p_values_CA[i], \"--\", color=my_colors[i] )\n",
    "    \n",
    "plt.xlabel(\"smoothing window\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.legend(loc=4)\n",
    "plt.close(fig12)\n",
    "fig12.savefig(plots_path+\"Window influence on correlation CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019245ac",
   "metadata": {},
   "source": [
    "# Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bd9d1",
   "metadata": {},
   "source": [
    "## The conversation contains three phases : pregame conversation (explanation of the rules, often a monologue), the guessing game, and postgame conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e5373",
   "metadata": {},
   "source": [
    "### Computing the correlation of each phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phases = ['PREGAME', 'GAME', 'POSTGAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr_files_AA = []\n",
    "nb_points_files_AA = []\n",
    "p_values_files_AA = []\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "\n",
    "    print(filename)\n",
    "    \n",
    "    list_corr = []\n",
    "        \n",
    "    df = pd.read_csv(path_AA+str(filename)+'.csv')\n",
    "    \n",
    "    corr_phases, nb_points, p_values = compute_corr_phases(df, Phases, \"Phases\", \"smoothed\", \"Speaker\", \"Global_start\")\n",
    "\n",
    "    p_values_files_AA.append(p_values)        \n",
    "    list_corr_files_AA.append(corr_phases)\n",
    "    nb_points_files_AA.append(nb_points)\n",
    "\n",
    "\n",
    "mean_corr = [my_mean([list_corr_files_AA[j][i] for i in range(len(list_corr_files_AA[j]))]) for j in range(len(list_corr_files_AA))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr_files_CA = []\n",
    "nb_points_files_CA = []\n",
    "p_values_files_CA = []\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    list_corr = []\n",
    "        \n",
    "    file = data_CA[i]\n",
    "\n",
    "    df = pd.read_csv(path_CA+str(filename)+'.csv')\n",
    "    \n",
    "    corr_phases, nb_points, p_values = compute_corr_phases(df, Phases, \"Phases\", \"smoothed\", \"Speaker\", \"Global_start\")\n",
    "\n",
    "    p_values_files_CA.append(p_values)\n",
    "    list_corr_files_CA.append(corr_phases)\n",
    "    nb_points_files_CA.append(nb_points)\n",
    "\n",
    "mean_corr = [my_mean([list_corr_files_CA[j][i] for i in range(len(list_corr_files_CA[j]))]) for j in range(len(list_corr_files_CA))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eaea13",
   "metadata": {},
   "source": [
    "### Plotting phases on the speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acde0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig13, axs13 = plt.subplots(9, 1, figsize=(15,20))\n",
    "\n",
    "for i, table in enumerate(data_AA) :\n",
    "    \n",
    "    filename = filenames_AA[i]\n",
    "    \n",
    "    axs13[i].set_xlabel('time')\n",
    "    axs13[i].set_ylabel('Speech rate')\n",
    "    axs13[i].plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], default_window, default_poly), label='Adult1',color = my_red)\n",
    "    axs13[i].plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], default_window, default_poly), label='Adult2', color=my_blue)\n",
    "    axs13[i].set_title(str(table['Filename'][0]))\n",
    "    axs13[i].legend()\n",
    "    \n",
    "    liste_phases = list(phases_AA[phases_AA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    for couple in liste_phases:\n",
    "        \n",
    "        label, time = couple\n",
    "\n",
    "        if \"1\" in label:\n",
    "            axs13[i].axvline(x=time, color='r')\n",
    "        elif \"2\" in label:\n",
    "            axs13[i].axvline(x=time, color='b')\n",
    "        else :\n",
    "            axs13[i].axvline(x=time, color='orange')\n",
    "            \n",
    "    if \"AA-MG-CH\" in filename:\n",
    "        fig135 = plt.figure(figsize=(20,5))\n",
    "        plt.plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], default_window, default_poly), label='Adult1',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], default_window, default_poly), label='Adult2', color=my_blue)\n",
    "        \n",
    "        for couple in liste_phases:\n",
    "        \n",
    "            label, time = couple\n",
    "\n",
    "            if \"1\" in label:\n",
    "                plt.axvline(x=time, color='r')\n",
    "            elif \"2\" in label:\n",
    "                plt.axvline(x=time, color='b')\n",
    "            else :\n",
    "                plt.axvline(x=time, color='orange')\n",
    "        \n",
    "        plt.close(fig135)\n",
    "        fig135.savefig(examples_path + \"Phases_SR_AA\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.close(fig13)\n",
    "fig13.savefig(plots_path+\"Phases and smoothed speech rate AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec930cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig14, axs14 = plt.subplots(9, 1, figsize=(15,20))\n",
    "\n",
    "for i, table in enumerate(data_CA) :\n",
    "    \n",
    "    filename = filenames_CA[i]\n",
    "    \n",
    "    axs14[i].set_xlabel('time')\n",
    "    axs14[i].set_ylabel('Speech rate')\n",
    "    axs14[i].plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'], default_window, default_poly), label='Parent',color = my_red)\n",
    "    axs14[i].plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], default_window, default_poly), label='Child', color=my_blue)\n",
    "    axs14[i].set_title(str(table['Filename'][0]))\n",
    "    axs14[i].legend()\n",
    "    \n",
    "    liste_phases = list(phases_CA[phases_CA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    for couple in liste_phases:\n",
    "        \n",
    "        label, time = couple\n",
    "\n",
    "        if \"1\" in label:\n",
    "            axs14[i].axvline(x=time, color='r')\n",
    "        elif \"2\" in label:\n",
    "            axs14[i].axvline(x=time, color='b')\n",
    "        else :\n",
    "            axs14[i].axvline(x=time, color='orange')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.close(fig14)\n",
    "fig14.savefig(plots_path+\"Phases and smoothed speech rate CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252173c",
   "metadata": {},
   "source": [
    "### Plotting correlation of each phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aba0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig15, axs15 = plt.subplots(3,1, figsize=(10,10))\n",
    "ax1, ax2, ax3 = axs15\n",
    "\n",
    "for i, list_corr in enumerate(list_corr_files_AA):\n",
    "    \n",
    "    ax1.plot(Phases, list_corr, 'o',label=str(filenames_AA[i]))\n",
    "    \n",
    "    ax2.plot(Phases, nb_points_files_AA[i],'o', label=str(filenames_AA[i]))\n",
    "    \n",
    "    ax3.plot(Phases, p_values_files_AA[i],'o', label=str(filenames_AA[i]))\n",
    "    \n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax2.yaxis.set_ticks_position('both')\n",
    "\n",
    "ax1.set_ylabel(\"correlation\")\n",
    "ax2.set_ylabel(\"number of utterances points\")\n",
    "ax3.set_ylabel(\"p_value\")\n",
    "\n",
    "ax1.legend(loc=(0.2, 0.05))\n",
    "ax2.legend(loc=(0.2, 0.05))\n",
    "ax3.legend(loc=(0.2, 0.05))\n",
    "\n",
    "plt.close(fig15)\n",
    "fig15.savefig(plots_path+\"Correlation by phase AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86246934",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig16, axs16 = plt.subplots(3,1, figsize=(10,10))\n",
    "ax1, ax2, ax3 = axs16\n",
    "\n",
    "for i, list_corr in enumerate(list_corr_files_CA):\n",
    "    \n",
    "    ax1.plot(Phases, list_corr, 'o',label=str(filenames_CA[i]))\n",
    "    \n",
    "    ax2.plot(Phases, nb_points_files_CA[i], 'o',label=str(filenames_CA[i]))\n",
    "    \n",
    "    ax3.plot(Phases, p_values_files_CA[i],'o', label=str(filenames_CA[i]))\n",
    "    \n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax2.yaxis.set_ticks_position('both')\n",
    "\n",
    "ax1.set_ylabel(\"correlation\")\n",
    "ax2.set_ylabel(\"number of utterances points\")\n",
    "ax3.set_ylabel(\"p_value\")\n",
    "\n",
    "ax1.legend(loc=(0.2, 0.05))\n",
    "ax2.legend(loc=(0.2, 0.05))\n",
    "ax3.legend(loc=(0.2, 0.05))\n",
    "\n",
    "plt.close(fig16)\n",
    "fig16.savefig(plots_path+\"Correlation by phase CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c69624",
   "metadata": {},
   "source": [
    "# Correlation by game role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e6358",
   "metadata": {},
   "source": [
    "## Each speaker is alternatively asking or answering the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roles_AA, Correlations_AA, p_values_AA = [],[], []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "\n",
    "    filename = filenames_AA[i]\n",
    "    \n",
    "    roles, correlations, p_values = compute_corr_roles(data, \"Roles\", \"Speech rate\", \"Speaker\", \"Global_start\")\n",
    "    \n",
    "    Roles_AA.append(roles)\n",
    "    Correlations_AA.append(correlations)\n",
    "    p_values_AA.append(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7852249",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig17, axs17 = plt.subplots(3,3, figsize=(10,10))\n",
    "\n",
    "\n",
    "for i in range(len(Roles_AA)):\n",
    "\n",
    "    axs17[i//3,i%3].plot(Roles_AA[i], Correlations_AA[i], 'o')\n",
    "    axs17[i//3,i%3].set_title(filenames_AA[i])\n",
    "\n",
    "plt.close(fig17)\n",
    "fig17.tight_layout()\n",
    "fig17.savefig(plots_path+\"Correlation by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roles_CA, Correlations_CA, p_values_CA = [],[], []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "\n",
    "    filename = filenames_CA[i]\n",
    "    \n",
    "    roles, correlations, p_values = compute_corr_roles(data, \"Roles\", \"Speech rate\", \"Speaker\", \"Global_start\")\n",
    "    \n",
    "    Roles_CA.append(roles)\n",
    "    Correlations_CA.append(correlations)\n",
    "    p_values_CA.append(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig18, axs18 = plt.subplots(3,3, figsize=(10,10))\n",
    "\n",
    "\n",
    "for i in range(len(Roles_CA)):\n",
    "\n",
    "    axs18[i//3,i%3].plot(Roles_CA[i], Correlations_CA[i], 'o')\n",
    "    axs18[i//3,i%3].set_title(filenames_CA[i])\n",
    "    \n",
    "plt.close(fig18)\n",
    "fig18.tight_layout()\n",
    "fig18.savefig(plots_path+\"Correlation by role CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b6b1b5",
   "metadata": {},
   "source": [
    "# Number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00165c1a",
   "metadata": {},
   "source": [
    "## Adult/adult vs Adult/child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f451fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_adult_1 = []\n",
    "nb_words_adult_2 = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_AA) :\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    \n",
    "    mean_1 = np.mean(data_1[\"Word\"])\n",
    "    mean_2 = np.mean(data_2[\"Word\"])\n",
    "    \n",
    "    nb_words_adult_1.append(mean_1)\n",
    "    nb_words_adult_2.append(mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_adult = []\n",
    "nb_words_child = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_CA) :\n",
    "    \n",
    "    \n",
    "    data_adult = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_child = data[data[\"Speaker\"]==\"Child\"]\n",
    "        \n",
    "    mean_adult = np.mean(data_adult[\"Word\"])\n",
    "    mean_child = np.mean(data_child[\"Word\"])\n",
    "    \n",
    "    nb_words_adult.append(mean_adult)\n",
    "    nb_words_child.append(mean_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8051b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig19, axs19 = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    axs19[0].plot([\"Adult 1\", \"Adult 2\"], [nb_words_adult_1[i], nb_words_adult_2[i]], 'o', label=filename)\n",
    "    \n",
    "axs19[0].axhline(y=np.mean(nb_words_adult_1), label=\"Adult1\", color='r')\n",
    "axs19[0].axhline(y=np.mean(nb_words_adult_2), label=\"Adult2\", color='b')\n",
    "\n",
    "for j, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    axs19[1].plot([\"Parent\", \"Child\"], [nb_words_adult[j], nb_words_child[j]], 'o', label=filename)\n",
    "    \n",
    "axs19[1].axhline(y=np.mean(nb_words_adult), label=\"Adult\", color='r')\n",
    "axs19[1].axhline(y=np.mean(nb_words_child), label=\"Child\", color='b')\n",
    "    \n",
    "axs19[0].set_title(\"Mean number of words for both adults\")\n",
    "axs19[1].set_title(\"Mean number of words for adult and child\")\n",
    "\n",
    "axs19[0].legend(loc=9,fontsize=8)\n",
    "axs19[1].legend(loc=9,fontsize=8)\n",
    "\n",
    "plt.close(fig19)\n",
    "fig19.savefig(plots_path+\"Mean number of words AA VS CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae6d25",
   "metadata": {},
   "source": [
    "## Coding roles in a more convenient way (ask or answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    roles_file = []\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        \n",
    "        if (data[\"Speaker\"][j]==\"Adult1\" and data[\"Roles\"][j]==\"SPEAKER1 \") or (data[\"Speaker\"][j]==\"Adult2\" and data[\"Roles\"][j]==\"SPEAKER2 \"):\n",
    "            roles_file.append(\"ans\")\n",
    "            \n",
    "        else:\n",
    "            roles_file.append(\"ask\")\n",
    "            \n",
    "    data[\"New_role\"]=roles_file\n",
    "    adapted_data_AA[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    roles_file = []\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        \n",
    "        if (data[\"Speaker\"][j]==\"Parent\" and data[\"Roles\"][j]==\"SPEAKER1 \") or (data[\"Speaker\"][j]==\"Child\" and data[\"Roles\"][j]==\"SPEAKER2 \"):\n",
    "            roles_file.append(\"ans\")\n",
    "            \n",
    "        else:\n",
    "            roles_file.append(\"ask\")\n",
    "            \n",
    "    data[\"New_role\"]=roles_file\n",
    "    adapted_data_CA[i] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcebb8",
   "metadata": {},
   "source": [
    "## Number of words by role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_1_ans = []\n",
    "adult_1_ask = []\n",
    "\n",
    "adult_2_ans = []\n",
    "adult_2_ask = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    \n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Word\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Word\"])\n",
    "    \n",
    "    adult_1_ans.append(mean_1_ans)\n",
    "    adult_1_ask.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Word\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Word\"])\n",
    "    \n",
    "    adult_2_ans.append(mean_2_ans)\n",
    "    adult_2_ask.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_ans = []\n",
    "adult_ask = []\n",
    "\n",
    "child_ans = []\n",
    "child_ask = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Word\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Word\"])\n",
    "    \n",
    "    adult_ans.append(mean_1_ans)\n",
    "    adult_ask.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Child\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Word\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Word\"])\n",
    "    \n",
    "    child_ans.append(mean_2_ans)\n",
    "    child_ask.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = [\"Adult 1\" for i in range(len(adult_1_ans)+len(adult_1_ask))]+[\"Adult 2\" for i in range(len(adult_2_ans)+len(adult_2_ask))]\n",
    "role = [\"Answer\" for i in range(len(adult_1_ans))] + [\"Ask\" for i in range(len(adult_1_ask))] + [\"Answer\" for i in range(len(adult_2_ans))]+ [\"Ask\" for i in range(len(adult_2_ask))]\n",
    "words = adult_1_ans + adult_1_ask + adult_2_ans + adult_2_ask\n",
    "dico_AA = {\"Speaker\":speaker, \"Role\":role,\"Words\":words}\n",
    "df_AA = pd.DataFrame(dico_AA)\n",
    "\n",
    "fig20 = sns.catplot(data=df_AA, kind=\"bar\", x=\"Role\", y=\"Words\", hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig20.despine(left=True)\n",
    "fig20.set_axis_labels(\"\", \"Mean number of words per utterance\")\n",
    "fig20.legend.set_title(\"\")\n",
    "\n",
    "fig20.savefig(plots_path+\"Mean nb of words by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = [\"Adult\" for i in range(len(adult_ans)+len(adult_ask))]+[\"Child\" for i in range(len(child_ans)+len(child_ask))]\n",
    "role = [\"Answer\" for i in range(len(adult_ans))] + [\"Ask\" for i in range(len(adult_ask))] + [\"Answer\" for i in range(len(child_ans))]+ [\"Ask\" for i in range(len(child_ask))]\n",
    "words = adult_ans + adult_ask + child_ans + child_ask\n",
    "dico_CA = {\"Speaker\":speaker, \"Role\":role,\"Words\":words}\n",
    "df_CA = pd.DataFrame(dico_CA)\n",
    "\n",
    "fig21 = sns.catplot(data=df_CA, kind=\"bar\", x=\"Role\", y=\"Words\",hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig21.despine(left=True)\n",
    "fig21.set_axis_labels(\"\", \"Mean number of words per utterance\")\n",
    "fig21.legend.set_title(\"\")\n",
    "\n",
    "fig21.savefig(plots_path+\"Mean nb of words by role CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c1396",
   "metadata": {},
   "source": [
    "# Mean speech rate by role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31250483",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_1_ans_SR = []\n",
    "adult_1_ask_SR = []\n",
    "\n",
    "adult_2_ans_SR = []\n",
    "adult_2_ask_SR = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    \n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Speech rate\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_1_ans_SR.append(mean_1_ans)\n",
    "    adult_1_ask_SR.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Speech rate\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_2_ans_SR.append(mean_2_ans)\n",
    "    adult_2_ask_SR.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b203a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_ans_SR = []\n",
    "adult_ask_SR = []\n",
    "\n",
    "child_ans_SR = []\n",
    "child_ask_SR = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Speech rate\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_ans_SR.append(mean_1_ans)\n",
    "    adult_ask_SR.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Child\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Speech rate\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Speech rate\"])\n",
    "    \n",
    "    child_ans_SR.append(mean_2_ans)\n",
    "    child_ask_SR.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57150a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = [\"Adult 1\" for i in range(len(adult_1_ans_SR)+len(adult_1_ask_SR))]+[\"Adult 2\" for i in range(len(adult_2_ans_SR)+len(adult_2_ask_SR))]\n",
    "role = [\"Answer\" for i in range(len(adult_1_ans_SR))] + [\"Ask\" for i in range(len(adult_1_ask_SR))] + [\"Answer\" for i in range(len(adult_2_ans_SR))]+ [\"Ask\" for i in range(len(adult_2_ask_SR))]\n",
    "SR = adult_1_ans_SR + adult_1_ask_SR + adult_2_ans_SR + adult_2_ask_SR\n",
    "dico_AA = {\"Speaker\":speaker, \"Role\":role,\"SR\":SR}\n",
    "df_AA = pd.DataFrame(dico_AA)\n",
    "\n",
    "fig22 = sns.catplot(data=df_AA, kind=\"bar\", x=\"Role\", y=\"SR\", hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig22.despine(left=True)\n",
    "fig22.set_axis_labels(\"\", \"Mean speech rate\")\n",
    "fig22.legend.set_title(\"\")\n",
    "\n",
    "fig22.savefig(plots_path+\"Mean SR by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = [\"Adult\" for i in range(len(adult_ans_SR)+len(adult_ask_SR))]+[\"Child\" for i in range(len(child_ans_SR)+len(child_ask_SR))]\n",
    "role = [\"Answer\" for i in range(len(adult_ans_SR))] + [\"Ask\" for i in range(len(adult_ask_SR))] + [\"Answer\" for i in range(len(child_ans_SR))]+ [\"Ask\" for i in range(len(child_ask_SR))]\n",
    "SR = adult_ans_SR + adult_ask_SR + child_ans_SR + child_ask_SR\n",
    "dico_CA = {\"Speaker\":speaker, \"Role\":role,\"SR\":SR}\n",
    "df_CA = pd.DataFrame(dico_CA)\n",
    "\n",
    "fig23 = sns.catplot(data=df_CA, kind=\"bar\", x=\"Role\", y=\"SR\",hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig23.despine(left=True)\n",
    "fig23.set_axis_labels(\"\", \"Mean SR per utterance\")\n",
    "fig23.legend.set_title(\"\")\n",
    "\n",
    "fig23.savefig(plots_path+\"Mean SR by role CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OK !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183f933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
